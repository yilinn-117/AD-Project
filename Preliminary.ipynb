{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "df = pd.read_csv('ADNI_merged_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = df.columns.tolist()\n",
    "#print(covariates)\n",
    "vital_var = ['VITALweight', 'VITALheight', 'VITALbloodpressDIA', 'VITALbloodpressSYS', 'VITALheartrate']\n",
    "blood_var = ['ALT', 'Alkaline_Pho', 'AST','Cholesterol','Creatine_kinase', 'Creatinine', 'Eosinophils', 'GGT', 'Glucose', 'Hematocrit', 'Hemoglobin', 'Lymphocytes', 'Monocytes', 'Platelets', 'Vitamin_B12', 'Triglycerides', 'Indirect_Bilirubin']\n",
    "demo_var = ['PTRACCAT', 'PTGENDER', 'PTEDUCAT', 'Age']\n",
    "ADAS_var = ['ADASword_recall', 'ADAScommands', 'ADASconstruction', 'ADASdelayed_word_recall', 'ADASnaming', 'ADASideational', 'ADASorientation', 'ADASword_recognation', 'ADASrem_instruction', 'ADAScomprehension', 'ADASword_finding', 'ADASspoken_language', 'ADAScancellation']\n",
    "MMSE_var = ['MMSE_orient', 'MMSE_regist', 'MMSE_attent', 'MMSE_recall', 'MMSE_language']\n",
    "CD_var =  ['CDMEMORY', 'CDORIENT', 'CDJUDGE', 'CDCOMMUN', 'CDHOME', 'CDCARE']\n",
    "misc_var = ['HMHYPERT', 'APOE4COUNT', 'TAU', 'PTAU']\n",
    "\n",
    "static_var = [blood_var, demo_var, misc_var]\n",
    "t_var = [ADAS_var, MMSE_var, CD_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the first 1000 patients \n",
    "df_first1000 = df[df['RID'].isin(df['RID'].unique()[:1000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using blood var as static var, MMSE m0 as t0 var, MMSE m6 as t1 var in our training set\n",
    "\n",
    "train_set = []\n",
    "\n",
    "for rid in df_first1000['RID'].unique():\n",
    "    baseline = df_first1000[(df_first1000['RID'] == 2) & (df_first1000['VISCODE2'] == 'm0')][blood_var].values.tolist()[0]\n",
    "    t0 = df_first1000[(df_first1000['RID'] == 2) & (df_first1000['VISCODE2'] == 'm0')][MMSE_var].values.tolist()[0]\n",
    "    t1 = df_first1000[(df_first1000['RID'] == 2) & (df_first1000['VISCODE2'] == 'm06')][MMSE_var].values.tolist()[0]\n",
    "    toAppend = baseline+t0+t1\n",
    "    \n",
    "    train_set.append(toAppend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:31,  6.58it/s]C:\\Users\\Teddywolf\\AppData\\Local\\Temp\\ipykernel_40476\\2878621193.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "100%|██████████| 1000/1000 [02:33<00:00,  6.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# visible nodes: baseline var, t0 var, t1 var\n",
    "node_visible = len(train_set[0])\n",
    "\n",
    "# hidden nodes: randomly chosen number (improve later with cross validation)\n",
    "node_hidden = 10\n",
    "\n",
    "# decide how much to update weight/bias each step\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize weights/bias\n",
    "# weight = interaction\n",
    "#[W_11,W_21,....,W_18_1,......W_23_1] -> hidden 1\n",
    "#[W_13,W_23,....,W_18_2,......W_23_2] -> hidden 2\n",
    "#[W_13,W_23,....,W_18_3,......W_23_3] -> hidden 3\n",
    "#.................................... -> more hidden\n",
    "# sva1,sva2,....,t0va1,.......t1va1,...\n",
    "\n",
    "W = np.full((node_hidden,node_visible),0.1)\n",
    "\n",
    "# bias = score for each individual node\n",
    "visible_bias = np.zeros(node_visible)\n",
    "hidden_bias = np.zeros(node_hidden)\n",
    "\n",
    "\n",
    "# contrastive divergence\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    for scenario in train_set:\n",
    "\n",
    "        # increase existing pattern's probability\n",
    "            # use gibb's sampling\n",
    "            # choose a possible scenario matching current scenario:\n",
    "        hidden_prob = np.sum(W*scenario,axis = 1)\n",
    "\n",
    "        chosen_hidden = []\n",
    "\n",
    "        for j in range(node_hidden):\n",
    "            chosen_hidden.append(np.random.binomial(1, sigmoid(hidden_bias[j]+hidden_prob[j])))\n",
    "        \n",
    "        \n",
    "        # decrease a random pattern's probability\n",
    "        \n",
    "        # Negative phase\n",
    "        neg_scenario = np.random.binomial(n=1 , p = 1/node_visible, size = node_visible)\n",
    "        \n",
    "        neg_hidden = np.random.binomial(n=1, p = 1/node_hidden, size = node_hidden)\n",
    "        \n",
    "\n",
    "        # update bias/weight according to scenario chosen\n",
    "        for k in range(len(scenario)):\n",
    "            if scenario[k] == 1:\n",
    "                visible_bias[k] += learning_rate\n",
    "            if neg_scenario[k] == 1:\n",
    "                visible_bias[k] -= learning_rate\n",
    "            for l in range(len(chosen_hidden)):\n",
    "                if scenario[k] == 1 and chosen_hidden[l] == 1:\n",
    "                    W[l,k] += learning_rate\n",
    "                if neg_scenario[k] == 1 and neg_hidden[l] == 1:\n",
    "                    W[l,k] -= learning_rate\n",
    "\n",
    "        for m in range(len(chosen_hidden)):\n",
    "            if chosen_hidden[m] == 1:\n",
    "                hidden_bias[m] += learning_rate\n",
    "            if neg_hidden[m] == 1:\n",
    "                hidden_bias[m] -= learning_rate\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -9947.20000002  -9964.90000002  -9911.30000002  -9969.30000002\n",
      " -10002.70000002 -10010.30000002  -9959.30000002  -9960.00000002\n",
      "  -9907.10000002 -10006.90000002]\n",
      "[-3726.1        -3722.8        -3696.7        -3672.7\n",
      " -3690.8        -3723.         -3690.6        -3729.8\n",
      " -3700.5        -3680.1        -3686.3        -3729.4\n",
      " -3706.3        -3703.6        -3713.         -3710.1\n",
      " -3682.         -3702.2        -3696.         -3695.3\n",
      " 96291.10000112 -3714.8        -3728.         -3735.1\n",
      " -3691.4        -3728.6        -3699.4       ]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_bias)\n",
    "print(visible_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do next:\n",
    "# generate energy function according to weight and bias.\n",
    "# Energy = ?\n",
    "\n",
    "# predict prob(xt+1 | xt, xs) = 1/Z * integral dz e^-energy\n",
    "\n",
    "# implement GAN to try to distinguish digital twin/ true patient\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ways to improve performance:\n",
    "cross validation for epoch, hidden node number, weight for gan, learning rate; normalization of variable, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
